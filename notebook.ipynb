{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 128)\n",
      "torch.Size([128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "from pre_process_2 import get_final\n",
    "import os\n",
    "from PIL import Image\n",
    "from pre_process_original import *\n",
    "import cv2\n",
    "from model import SegmentationModel\n",
    "\n",
    "\n",
    "root = os.getcwd()\n",
    "data = \"Data\"\n",
    "cellname = \"cell02_APPL1_GFP\"\n",
    "imgs = list(sorted(os.listdir(os.path.join(root, data,cellname))))\n",
    "\n",
    "img_path = os.path.join(root,data,cellname, imgs[0])\n",
    "\n",
    "img = get_final(img_path, False)\n",
    "\n",
    "d = img.shape[0]\n",
    "img_array = []\n",
    "for i in range (0,d):\n",
    "    m_new = img[i]\n",
    "    img_array.append(np.array(m_new, dtype=np.float32))\n",
    "\n",
    "k = np.amax(img_array)\n",
    "img_array = np.array(img_array)\n",
    "img_array = (img_array)/float(k)\n",
    "\n",
    "img_array = np.expand_dims(img_array,axis=0)\n",
    "print(img_array.shape)\n",
    "\n",
    "model = SegmentationModel(checkpoint=\"checkpoint_train.pth.tar\", mode=\"eval\")\n",
    "\n",
    "mask = model.inference(img_array)\n",
    "\n",
    "print(mask.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_binary_image2(img: Image):\n",
    " \n",
    "        images = []\n",
    "        for i in range (0,img.n_frames):\n",
    "            res = img.seek(i)\n",
    "            images.append(np.array(img,dtype=np.float32))\n",
    "        images = np.array(images,dtype=np.float32)\n",
    "        # 80,608,400\n",
    "        #image.shape = 608,608,608\n",
    "        d = images.shape[0]\n",
    "        h = images.shape[1]\n",
    "        w = images.shape[2]\n",
    "\n",
    "        max_dim = max(max(h,w),d)\n",
    "        print(max_dim)\n",
    "\n",
    "        d_up = int(math.ceil(float((max_dim-d)/2)))\n",
    "        d_down = int(math.floor(float((max_dim-d)/2)))\n",
    "        print(d_up,d_down)\n",
    "\n",
    "        w_up = int(math.ceil(float((max_dim-w)/2)))\n",
    "        w_down = int(math.floor(float((max_dim-w)/2)))\n",
    "        print(w_up,w_down)\n",
    "\n",
    "        h_up = int(math.ceil(float((max_dim-h)/2)))\n",
    "        h_down = int(math.floor(float((max_dim-h)/2)))\n",
    "        print(h_up,h_down)\n",
    "\n",
    "        images = np.pad(images,((d_up,d_down),(0,0),(0,0)),'wrap')\n",
    "        print(images.shape)\n",
    "        images = np.pad(images,((0,0),(0,0),(w_up,w_down)),'wrap')\n",
    "        print(images.shape)\n",
    "        images = np.pad(images,((0,0),(h_up,h_down),(0,0)),'wrap')\n",
    "        \n",
    "        print(images.shape)\n",
    "\n",
    "        return (images,d,h,w,max_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608\n",
      "264 264\n",
      "104 104\n",
      "0 0\n",
      "(608, 608, 400)\n",
      "(608, 608, 608)\n",
      "(608, 608, 608)\n",
      "output:  (80, 608, 400, 608)\n",
      "264.0\n",
      "start:  265 end:  393\n",
      "265 (608, 608) (128, 128)\n",
      "266 (608, 608) (128, 128)\n",
      "267 (608, 608) (128, 128)\n",
      "268 (608, 608) (128, 128)\n",
      "269 (608, 608) (128, 128)\n",
      "270 (608, 608) (128, 128)\n",
      "271 (608, 608) (128, 128)\n",
      "272 (608, 608) (128, 128)\n",
      "273 (608, 608) (128, 128)\n",
      "274 (608, 608) (128, 128)\n",
      "275 (608, 608) (128, 128)\n",
      "276 (608, 608) (128, 128)\n",
      "277 (608, 608) (128, 128)\n",
      "278 (608, 608) (128, 128)\n",
      "279 (608, 608) (128, 128)\n",
      "280 (608, 608) (128, 128)\n",
      "281 (608, 608) (128, 128)\n",
      "282 (608, 608) (128, 128)\n",
      "283 (608, 608) (128, 128)\n",
      "284 (608, 608) (128, 128)\n",
      "285 (608, 608) (128, 128)\n",
      "286 (608, 608) (128, 128)\n",
      "287 (608, 608) (128, 128)\n",
      "288 (608, 608) (128, 128)\n",
      "289 (608, 608) (128, 128)\n",
      "290 (608, 608) (128, 128)\n",
      "291 (608, 608) (128, 128)\n",
      "292 (608, 608) (128, 128)\n",
      "293 (608, 608) (128, 128)\n",
      "294 (608, 608) (128, 128)\n",
      "295 (608, 608) (128, 128)\n",
      "296 (608, 608) (128, 128)\n",
      "297 (608, 608) (128, 128)\n",
      "298 (608, 608) (128, 128)\n",
      "299 (608, 608) (128, 128)\n",
      "300 (608, 608) (128, 128)\n",
      "301 (608, 608) (128, 128)\n",
      "302 (608, 608) (128, 128)\n",
      "303 (608, 608) (128, 128)\n",
      "304 (608, 608) (128, 128)\n",
      "305 (608, 608) (128, 128)\n",
      "306 (608, 608) (128, 128)\n",
      "307 (608, 608) (128, 128)\n",
      "308 (608, 608) (128, 128)\n",
      "309 (608, 608) (128, 128)\n",
      "310 (608, 608) (128, 128)\n",
      "311 (608, 608) (128, 128)\n",
      "312 (608, 608) (128, 128)\n",
      "313 (608, 608) (128, 128)\n",
      "314 (608, 608) (128, 128)\n",
      "315 (608, 608) (128, 128)\n",
      "316 (608, 608) (128, 128)\n",
      "317 (608, 608) (128, 128)\n",
      "318 (608, 608) (128, 128)\n",
      "319 (608, 608) (128, 128)\n",
      "320 (608, 608) (128, 128)\n",
      "321 (608, 608) (128, 128)\n",
      "322 (608, 608) (128, 128)\n",
      "323 (608, 608) (128, 128)\n",
      "324 (608, 608) (128, 128)\n",
      "325 (608, 608) (128, 128)\n",
      "326 (608, 608) (128, 128)\n",
      "327 (608, 608) (128, 128)\n",
      "328 (608, 608) (128, 128)\n",
      "329 (608, 608) (128, 128)\n",
      "330 (608, 608) (128, 128)\n",
      "331 (608, 608) (128, 128)\n",
      "332 (608, 608) (128, 128)\n",
      "333 (608, 608) (128, 128)\n",
      "334 (608, 608) (128, 128)\n",
      "335 (608, 608) (128, 128)\n",
      "336 (608, 608) (128, 128)\n",
      "337 (608, 608) (128, 128)\n",
      "338 (608, 608) (128, 128)\n",
      "339 (608, 608) (128, 128)\n",
      "340 (608, 608) (128, 128)\n",
      "341 (608, 608) (128, 128)\n",
      "342 (608, 608) (128, 128)\n",
      "343 (608, 608) (128, 128)\n",
      "344 (608, 608) (128, 128)\n",
      "345 (608, 608) (128, 128)\n",
      "346 (608, 608) (128, 128)\n",
      "347 (608, 608) (128, 128)\n",
      "348 (608, 608) (128, 128)\n",
      "349 (608, 608) (128, 128)\n",
      "350 (608, 608) (128, 128)\n",
      "351 (608, 608) (128, 128)\n",
      "352 (608, 608) (128, 128)\n",
      "353 (608, 608) (128, 128)\n",
      "354 (608, 608) (128, 128)\n",
      "355 (608, 608) (128, 128)\n",
      "356 (608, 608) (128, 128)\n",
      "357 (608, 608) (128, 128)\n",
      "358 (608, 608) (128, 128)\n",
      "359 (608, 608) (128, 128)\n",
      "360 (608, 608) (128, 128)\n",
      "361 (608, 608) (128, 128)\n",
      "362 (608, 608) (128, 128)\n",
      "363 (608, 608) (128, 128)\n",
      "364 (608, 608) (128, 128)\n",
      "365 (608, 608) (128, 128)\n",
      "366 (608, 608) (128, 128)\n",
      "367 (608, 608) (128, 128)\n",
      "368 (608, 608) (128, 128)\n",
      "369 (608, 608) (128, 128)\n",
      "370 (608, 608) (128, 128)\n",
      "371 (608, 608) (128, 128)\n",
      "372 (608, 608) (128, 128)\n",
      "373 (608, 608) (128, 128)\n",
      "374 (608, 608) (128, 128)\n",
      "375 (608, 608) (128, 128)\n",
      "376 (608, 608) (128, 128)\n",
      "377 (608, 608) (128, 128)\n",
      "378 (608, 608) (128, 128)\n",
      "379 (608, 608) (128, 128)\n",
      "380 (608, 608) (128, 128)\n",
      "381 (608, 608) (128, 128)\n",
      "382 (608, 608) (128, 128)\n",
      "383 (608, 608) (128, 128)\n",
      "384 (608, 608) (128, 128)\n",
      "385 (608, 608) (128, 128)\n",
      "386 (608, 608) (128, 128)\n",
      "387 (608, 608) (128, 128)\n",
      "388 (608, 608) (128, 128)\n",
      "389 (608, 608) (128, 128)\n",
      "390 (608, 608) (128, 128)\n",
      "391 (608, 608) (128, 128)\n",
      "392 (608, 608) (128, 128)\n",
      "(128, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_final2(path_dir_1,mask):\n",
    "    \n",
    "    img = Image.open(path_dir_1)\n",
    "    \n",
    "    output = get_binary_image2(img)\n",
    "    images = output[0]\n",
    "    d = output[1]\n",
    "    h = output[2]\n",
    "    w = output[3]\n",
    "    max_dim = output[4]\n",
    "\n",
    "    print(\"output: \", output[1:])\n",
    "    print((max_dim-d)/2)\n",
    "    start = math.ceil(float((max_dim-d)/2))\n",
    "    if (start!=0):\n",
    "        start = start+1\n",
    "    end = start+128\n",
    "    print(\"start: \", start, \"end: \", end)\n",
    "    \n",
    "    final = []\n",
    "\n",
    "    for i in range (start,end):\n",
    "        img = images[i]\n",
    "        res = cv2.resize(img, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "        print(i, img.shape, res.shape)\n",
    "        final.append(np.array(res))\n",
    "\n",
    "    out = np.array(final)\n",
    "    print(out.shape)\n",
    " \n",
    "    return out\n",
    "\n",
    "\n",
    "img2 = get_final2(img_path, False)\n",
    "\n",
    "assert np.array_equal(img, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Checkpoint\n",
      "Loaded 200 test images from /Users/patrickcleeve/Documents/university/bio/demarco/4D-Segmentation/Data/cell02_APPL1_GFP.\n",
      "Loaded checkpoint: checkpoint_train.pth.tar on cpu device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Image 0/200: Model Inference:   0%|          | 0/200 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE:  <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import test\n",
    "\n",
    "test.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from pre_process_2 import get_final, get_binary_image\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "from tifffile import imsave\n",
    "from pre_process_original import *\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def get_final_old(path_dir_1, mask, truth: bool):\n",
    "\n",
    "    if truth:\n",
    "        img = Image.open(path_dir_1)\n",
    "        output = get_binary_image(img)\n",
    "        images = output[0]\n",
    "        return np.array(images)\n",
    "\n",
    "    else:\n",
    "        img = Image.open(path_dir_1)\n",
    "        output = get_binary_image(img)\n",
    "        images = output[0]\n",
    "        d = output[1]\n",
    "        h = output[2]\n",
    "        w = output[3]\n",
    "        max_dim = output[4]\n",
    "\n",
    "        start = math.ceil(float((max_dim - d) / 2))\n",
    "        if start != 0:\n",
    "            start = start + 1\n",
    "        end = start + 128\n",
    "\n",
    "        final = []\n",
    "\n",
    "        for i in range(start, end):\n",
    "            img = images[i]\n",
    "            res = cv2.resize(img, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "            final.append(np.array(res))\n",
    "\n",
    "        out = np.array(final)\n",
    "        # print(out.shape)\n",
    "\n",
    "        return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "fname = \"test1.tif\"\n",
    "\n",
    "img1 = get_final(fname, False, downsample=False)\n",
    "img2 = get_final(fname, False, downsample=True)\n",
    "img11 = get_final_old(fname, False, truth=True)\n",
    "img22 = get_final_old(fname, False, truth=False)\n",
    "\n",
    "\n",
    "assert np.array_equal(img1, img11)\n",
    "assert np.array_equal(img2, img22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fad936386847c0690ef09f89354cac38d1fac60e10a6477ddec627b925734645"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('4d_segmentation': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
